{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIK Data Cleaning\n",
    "\n",
    "- Remember to set Python kernel to 3 (not later).\n",
    "- Install additional packages `textblob`, `wordcloud`, and `gensim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import packages for scraping webpage contents and making sense of them\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variables and lists to serve as argument placeholders for scraping\n",
    "\n",
    "- ### `get` works in conjunction with `requests`.\n",
    "- ### `BeautifulSoup` must have a particular HTML element from a webpage to work on.\n",
    "  + #### In this case, `class=\"post-content\">`, and the *p* is from `<p style=...>`.\n",
    "  + #### Each website might have its own HTML structure; so might need different `soup.find` argument for each site being scraped.  \n",
    "    * #### E.g., `class_=\"css-53u6y8\"` works for a NYTimes.com article, along with  *p* which is standard in HTML to represent a paragraph of text.\n",
    "    * #### E.g., `class_=\"repo-list\"` works for GitHub search results.\n",
    "    * #### E.g., `li class_=\"b_algo\"` with *a* works for Bing search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\nHello there!  \n\n\nThis tool takes your search query, \n\napplies it to both major search engines, \n\nand then displays a simple comparison of the resulting search engine results.  \n\nAnalysis is limited to the first 100 results from each search engine.\n"
    }
   ],
   "source": [
    "#### Ask user for input\n",
    "\n",
    "os.system('clear')\n",
    "\n",
    "print(\"\\n\\nHello there!  \\n\\n\\nThis tool takes your search query, \\n\\napplies it to both major search engines, \\n\\nand then displays a simple comparison of the resulting search engine results.  \\n\\nAnalysis is limited to the first 100 results from each search engine.\")\n",
    "\n",
    "search_query = input(\"\\n\\n\\nWhat should we search for? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Set URL of page\n",
    "query_url_bing = requests.get('https://www.bing.com/search?'+'q='+search_query+'&count=1000').text\n",
    "query_url_google = requests.get('https://www.google.com/search?'+'q='+search_query+'&num=1000').text\n",
    "\n",
    "#### Pass URL of page into `BeautifulSoup` method\n",
    "query_html_bing = BeautifulSoup(query_url_bing, 'lxml')\n",
    "query_html_google = BeautifulSoup(query_url_google, \"html.parser\")\n",
    "\n",
    "#### Display well-formatted HTML results\n",
    "##### print (source_html.prettify())\n",
    "\n",
    "#### Extract one result title\n",
    "##### result_title = source_html.find('div', class_='f4 text-normal').text\n",
    "#### Extract one result description\n",
    "##### result_desc = source_html.find('p', class_='mb-1').text\n",
    "\n",
    "#### Display one (ie, first) result and title\n",
    "##### print (result_title)\n",
    "##### print (result_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Prepare output file\n",
    "\n",
    "import csv # CSV module\n",
    "from datetime import datetime\n",
    "\n",
    "##### Check existing records in file, to which we will append\n",
    "\n",
    "# with open('/Users/vix/Repos/Python-Learning/src/NLP/Intro to NLP Alice Zhao/Search_Results_Combined.csv','r') as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file)\n",
    "#     for line in csv_reader:\n",
    "#         print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Extract each search result's title and append to CSV file\n",
    "\n",
    "with open('/Users/vix/Repos/Python-Learning/src/NLP/Intro to NLP Alice Zhao/Search_Results_Combined.csv','a') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    # Since using csv.writer in append mode, no need for header row\n",
    "    # csv_writer.writerow(['Search_Engine','Search_Query','Result_Title'])\n",
    "\n",
    "    ##### Specifications for Bing\n",
    "    for result in query_html_bing.find_all('li', attrs = {'class':'b_algo'}):\n",
    "        result_title_bing = result.find('a').text\n",
    "        # print(result_title_bing)\n",
    "        csv_writer.writerow([datetime.today(),\"Bing\",search_query,result_title_bing])\n",
    "\n",
    "    ##### Specifications for Google\n",
    "    for result in query_html_google.find_all('h3', attrs = {'class':'zBAuLc'}):\n",
    "        result_title_google = result.find('div').text\n",
    "        # print(result_title_google)\n",
    "        csv_writer.writerow([datetime.today(),\"Google\",search_query,result_title_google])\n",
    "\n",
    "csv_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_transcript(url):\n",
    "    '''Returns HTML contents of specified site.'''\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    # text = [p.text for p in soup.find(class_=\"post-content\").find_all('p')]\n",
    "    # text = [p.text for p in soup.find(class_=\"mb-1\").find_all('my')]\n",
    "    text = [p.text for p in soup.title.string]\n",
    "    print(url)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Populate list of URLs\n",
    "\n",
    "# urls = ['http://scrapsfromtheloft.com/2017/05/06/louis-ck-oh-my-god-full-transcript/']\n",
    "urls = ['https://github.com/search?q=python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Actually perform scrape of contents of scrapsfromtheloft.com\n",
    "\n",
    "transcripts = [url_to_transcript(u) for u in urls]\n",
    "print (transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pickling: Saving results of some operation for future use, to be referenced by other Python programs.\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}